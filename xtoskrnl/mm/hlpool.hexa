/// Allocates physical memory for kernel hardware layer before memory manager gets initialized.
/// 
/// @param PageCount
///        Supplies the number of pages to be allocated.
/// 
/// @param Aligned
///        Specifies whether allocated memory should be aligned to 64k boundary or not.
/// 
/// @param Buffer
///        Supplies a buffer that receives the physical address.
/// 
/// @return This routine returns a status code.
/// 
/// @since XT 1.0
fun mmAllocateHardwareMemory(pageCount PFN_NUMBER, aligned BOOLEAN, buffer PULONG_PTR) {
	let descriptor = new ByValue<PLOADER_MEMORY_DESCRIPTOR>()

	let extraDescriptor = new ByValue<PLOADER_MEMORY_DESCRIPTOR>()

	let hardwareDescriptor = new ByValue<PLOADER_MEMORY_DESCRIPTOR>()

	var alignment PFN_NUMBER
	var maxPage PFN_NUMBER
	var physicalAddress ULONGLONG
	let listEntry = new ByValue<PLIST_ENTRY>()

	buffer[0] = 0
	maxPage = 4294967295 >> 12
	if (mmpUsedHardwareAllocationDescriptors + 2) > 64 {
		return (3221225626 as! XTSTATUS)

	}

	listEntry = keInitializationBlock.memoryDescriptorListHead.flink
	while listEntry != keInitializationBlock.memoryDescriptorListHead {
		descriptor = (((listEntry) as! Char * - [unknown clang ast] resolve OffsetOfExpr) as! LOADER_MEMORY_DESCRIPTOR *)
		alignment = (aligned) ? (((descriptor.basePage + 15) & ~15) - descriptor.basePage) : 0
		if descriptor.memoryType == loaderFree {
			if descriptor.basePage and ((descriptor.basePage + pageCount + alignment) < maxPage) and (descriptor.pageCount >= (pageCount + alignment)) {
				physicalAddress = (descriptor.basePage + alignment) << 12
				break
			}


		}

		listEntry = listEntry.flink

	}

	if listEntry == keInitializationBlock.memoryDescriptorListHead {
		return (3221225626 as! XTSTATUS)

	}

	hardwareDescriptor = mmpHardwareAllocationDescriptors[mmpUsedHardwareAllocationDescriptors]
	hardwareDescriptor.basePage = descriptor.basePage + alignment
	hardwareDescriptor.memoryType = loaderHardwareCachedMemory
	hardwareDescriptor.pageCount = pageCount
	mmpUsedHardwareAllocationDescriptors++	if alignment {
		if descriptor.pageCount > (pageCount + alignment) {
			extraDescriptor = mmpHardwareAllocationDescriptors[mmpUsedHardwareAllocationDescriptors]
			extraDescriptor.basePage = descriptor.basePage + alignment + pageCount as! ULONG
			extraDescriptor.memoryType = loaderFree
			extraDescriptor.pageCount = descriptor.pageCount - (alignment + pageCount as! ULONG)
			mmpUsedHardwareAllocationDescriptors++			rtlInsertHeadList(descriptor.listEntry, extraDescriptor.listEntry)

		}

		descriptor.pageCount = alignment
		rtlInsertHeadList(descriptor.listEntry, hardwareDescriptor.listEntry)

	} else {
		descriptor.basePage += pageCount as! ULONG
		descriptor.pageCount -= pageCount as! ULONG
		rtlInsertTailList(descriptor.listEntry, hardwareDescriptor.listEntry)
		if descriptor.pageCount == 0 {
			rtlRemoveEntryList(descriptor.listEntry)

		}


	}

	buffer[0] = physicalAddress
	return (0 as! XTSTATUS)
}

/// Maps physical address to the virtual memory area used by kernel hardware layer.
/// 
/// @param PhysicalAddress
///        Supplies the physical address to map.
/// 
/// @param PageCount
///        Supplies the number of pages to be mapped.
/// 
/// @param FlushTlb
///        Specifies whether to flush the TLB or not.
/// 
/// @param VirtualAddress
///        Supplies a buffer that receives the virtual address of the mapped pages.
/// 
/// @return This routine returns a status code.
/// 
/// @since XT 1.0
fun mmMapHardwareMemory(physicalAddress PHYSICAL_ADDRESS, pageCount PFN_NUMBER, flushTlb BOOLEAN, virtualAddress PVOID *) {
	var baseAddress PVOID
	var returnAddress PVOID
	var mappedPages PFN_NUMBER
	let ptePointer = new ByValue<PHARDWARE_PTE>()

	baseAddress = mmpHardwareHeapStart
	mappedPages = 0
	returnAddress = baseAddress
	virtualAddress[0] = (0 as! PVOID)
	while mappedPages < pageCount {
		if baseAddress == (0 as! PVOID) {
			return (3221225626 as! XTSTATUS)

		}

		ptePointer = mmpGetPteAddress(returnAddress) as! PHARDWARE_PTE
		returnAddress = returnAddress as! ULONG_PTR as! PVOID + 4096
		if ptePointer.valid {
			baseAddress = returnAddress
			mappedPages = 0
			continue
		}

		mappedPages++
	}

	returnAddress = (baseAddress + ((PhysicalAddress..lowPart as! ULONG_PTR & (4096 - 1)) as! ULONG)) as! ULONG_PTR as! PVOID
	if baseAddress == mmpHardwareHeapStart {
		mmpHardwareHeapStart = (baseAddress as! ULONG_PTR + (pageCount as! ULONG_PTR << 12)) as! PVOID

	}

	while --mappedPages {
		ptePointer = mmpGetPteAddress(baseAddress) as! PHARDWARE_PTE
		ptePointer.pageFrameNumber = (PhysicalAddress.QuadPart >> 12) as! PFN_NUMBER
		ptePointer.valid = 1
		ptePointer.writable = 1
		PhysicalAddress.QuadPart += 4096
		baseAddress = (baseAddress as! ULONG_PTR + 4096) as! PVOID

	}

	if flushTlb {
		mmFlushTlb()

	}

	if keDbgPrint {

		keDbgPrint("Virtual address: %P\n", returnAddress)
	}

	virtualAddress[0] = returnAddress
	return (0 as! XTSTATUS)
}

/// Marks existing mapping as CD/WT to avoid delays in write-back cache.
/// 
/// @param VirtualAddress
///        Supplies the virtual address region to mark as CD/WT.
/// 
/// @param PageCount
///        Supplies the number of mapped pages.
/// 
/// @return This routine does not return any value.
/// 
/// @since XT 1.0
fun mmMarkHardwareMemoryWriteThrough(virtualAddress PVOID, pageCount PFN_NUMBER) {
	let ptePointer = new ByValue<PHARDWARE_PTE>()

	var page PFN_NUMBER
	ptePointer = mmpGetPteAddress(virtualAddress) as! PHARDWARE_PTE
	[unknown clang ast] CompoundStmt ForStmt
}

/// Remaps the PTE to new physical address.
/// 
/// @param VirtualAddress
///        Supplies the virtual address to remap.
/// 
/// @param PhysicalAddress
///        Supplies a new physical address.
/// 
/// @param FlushTlb
///        Specifies whether to flush the TLB or not.
/// 
/// @return This routine does not return any value.
/// 
/// @since XT 1.0
fun mmRemapHardwareMemory(virtualAddress PVOID, physicalAddress PHYSICAL_ADDRESS, flushTlb BOOLEAN) {
	let ptePointer = new ByValue<PHARDWARE_PTE>()

	ptePointer = mmpGetPteAddress(virtualAddress) as! PHARDWARE_PTE
	ptePointer.pageFrameNumber = (PhysicalAddress.QuadPart >> 12) as! PFN_NUMBER
	ptePointer.valid = 1
	ptePointer.writable = 1
	if flushTlb {
		mmFlushTlb()

	}

}

/// Unmaps a Page Table Entry corresponding to the given virtual address.
/// 
/// @param VirtualAddress
///        Supplies the virtual address to unmap.
/// 
/// @param PageCount
///        Supplies the number of mapped pages.
/// 
/// @param FlushTlb
///        Specifies whether to flush the TLB or not.
/// 
/// @return This routine returns a status code.
/// 
/// @since XT 1.0
fun mmUnmapHardwareMemory(virtualAddress PVOID, pageCount PFN_NUMBER, flushTlb BOOLEAN) {
	let ptePointer = new ByValue<PHARDWARE_PTE>()

	var page PFN_NUMBER
	if virtualAddress < 18446744073705357312 as! PVOID {
		return (3221225485 as! XTSTATUS)

	}

	virtualAddress = (virtualAddress as! ULONG_PTR & ~(4096 - 1)) as! PVOID
	ptePointer = mmpGetPteAddress(virtualAddress) as! PHARDWARE_PTE
	[unknown clang ast] CompoundStmt ForStmt
	if flushTlb {
		mmFlushTlb()

	}

	if mmpHardwareHeapStart > virtualAddress {
		mmpHardwareHeapStart = virtualAddress

	}

	return (0 as! XTSTATUS)
}
